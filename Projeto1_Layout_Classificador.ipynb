{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - CiÃªncia dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: Athur Fonseca\r\n",
    "\r\n",
    "Nome: Caio Tieri\r\n",
    "\r\n",
    "Nome: Leonardo Andrade"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "AtenÃ§Ã£o: SerÃ£o permitidos grupos de trÃªs pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarÃ£o fazer um questionÃ¡rio de avaliaÃ§Ã£o de trabalho em equipe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "#import emoji\r\n",
    "\r\n",
    "#.get_emoji_regexp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Esperamos trabalhar no diretÃ³rio')\r\n",
    "print(os.getcwd())"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e nÃ£o relevantes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filename = 'Bis 1-340.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train = pd.read_excel(filename)\r\n",
    "train.head(5)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test.head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "## Classificador automÃ¡tico de sentimento\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FaÃ§a aqui uma descriÃ§Ã£o do seu produto e o que considerou como relevante ou nÃ£o relevante na classificaÃ§Ã£o dos tweets.\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "O produto Ã© um chocolate marcado por trazer um sentimento de insaciedade e vontade de comer sempre mais um.\r\n",
    "\r\n",
    "# Para julgar a relevÃ¢ncia dos tweets seguimos o critÃ©rio abaixo:\r\n",
    "\r\n",
    "1(Irrelevante): NÃ£o cita o produto ou cita o nome 'bis' mas se referindo a outra coisa.\r\n",
    "\r\n",
    "2(neutro): Fala do produto mas este nÃ£o se encaixa como o assunto principal do tweet\r\n",
    "\r\n",
    "2(relevante): Cita o produto como assunto principal, expressa indiretamente uma opiniÃ£o sobre o produto\r\n",
    "\r\n",
    "4(muito relevante): Cita o produto  como assunto principal do tweet e expressa uma opiniÃ£o clara sobre o mesmo."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "treino = train.iloc[:,[0,1]]\r\n",
    "treino.tail(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#importando funÃ§Ãµes\r\n",
    "\r\n",
    "import re \r\n",
    "\r\n",
    "\r\n",
    "def cleanup(text):\r\n",
    "    \"\"\"\r\n",
    "        FunÃ§Ã£o de limpeza muito simples que troca alguns sinais bÃ¡sicos por espaÃ§os\r\n",
    "    \"\"\"\r\n",
    "    #import string\r\n",
    "    punctuation = '[!-.:?;|\"]' # Note que os sinais [] sÃ£o delimitadores de um conjunto.\r\n",
    "    pattern = re.compile(punctuation)\r\n",
    "    text_subbed = re.sub(pattern, '', text)\r\n",
    "    return text_subbed\r\n",
    "    \r\n",
    "def tiraarroba (string):\r\n",
    "    palavras = []\r\n",
    "    lista = string.split()\r\n",
    "    for p in lista:\r\n",
    "        if p[0] == '@':\r\n",
    "            palavras.append(p)\r\n",
    "    for palavra in palavras:\r\n",
    "        lista.remove(palavra)\r\n",
    "    limpo = ' '.join(lista)\r\n",
    "    return limpo\r\n",
    "\r\n",
    "def tiralink (string):\r\n",
    "    palavras = []\r\n",
    "    lista = string.split()\r\n",
    "    for p in lista:\r\n",
    "        if p[0] == 'h' and p[1] == 't' and p[2] == 't' and p[3] == 'p' and p[4] == 's':\r\n",
    "            palavras.append(p)\r\n",
    "    for palavra in palavras:\r\n",
    "        lista.remove(palavra)\r\n",
    "    limpo = ' '.join(lista)\r\n",
    "    return limpo\r\n",
    "\r\n",
    "def tiralinha (string):\r\n",
    "    palavras = []\r\n",
    "    lista = string.split()\r\n",
    "    for p in lista:\r\n",
    "        limpo = p.rstrip(\"\\n\")\r\n",
    "        palavras.append(limpo)\r\n",
    "    tweet = \" \".join(palavras)\r\n",
    "    return tweet\r\n",
    "\r\n",
    "\r\n",
    "print(tiralinha('eu quero replay kkkk \\nvamo de novo no bis'))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Removendo caracteres indesejados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "treino['Treinamento'] = treino['Treinamento'].apply(cleanup)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#tira os @fulano citados\r\n",
    "\r\n",
    "i=0\r\n",
    "\r\n",
    "for t in treino.Treinamento:\r\n",
    "   limpo = tiraarroba(t)\r\n",
    "   treino.loc[i,'Treinamento'] = limpo\r\n",
    "   i+=1\r\n",
    "    \r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#retira os links (https)\r\n",
    "\r\n",
    "i=0\r\n",
    "\r\n",
    "for t in treino.Treinamento:\r\n",
    "   limpo = tiralink(t)\r\n",
    "   treino.loc[i,'Treinamento'] = limpo\r\n",
    "   i+=1\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "treino.head(50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "irrelevante = treino.loc[treino['NÃ­vel de RelevÃ¢ncia']==1,['Treinamento']]\r\n",
    "\r\n",
    "neutro = treino.loc[treino['NÃ­vel de RelevÃ¢ncia']==2,['Treinamento']]\r\n",
    "\r\n",
    "relevante = treino.loc[treino['NÃ­vel de RelevÃ¢ncia']==3,['Treinamento']]\r\n",
    "\r\n",
    "muito_relevante = treino.loc[treino['NÃ­vel de RelevÃ¢ncia']==4,['Treinamento']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lista_palavras=[]\r\n",
    "\r\n",
    "for tweet in treino['Treinamento']:\r\n",
    "    lista = tweet.split()\r\n",
    "    for p in lista:\r\n",
    "        lista_palavras.append(p)\r\n",
    "\r\n",
    "lista_irrelevante=[]\r\n",
    "\r\n",
    "for tweet in irrelevante['Treinamento']:\r\n",
    "    lista2 = tweet.split()\r\n",
    "    for p in lista2:\r\n",
    "        lista_irrelevante.append(p)\r\n",
    "\r\n",
    "lista_neutro = []\r\n",
    "\r\n",
    "for tweet in neutro['Treinamento']:\r\n",
    "    lista3 = tweet.split()\r\n",
    "    for p in lista3:\r\n",
    "        lista_neutro.append(p)\r\n",
    "\r\n",
    "lista_relevante = []\r\n",
    "\r\n",
    "for tweet in relevante['Treinamento']:\r\n",
    "    lista4 = tweet.split()\r\n",
    "    for p in lista4:\r\n",
    "        lista_relevante.append(p)\r\n",
    "\r\n",
    "lista_muito_relevante = []\r\n",
    "\r\n",
    "for tweet in muito_relevante['Treinamento']:\r\n",
    "    lista5 = tweet.split()\r\n",
    "    for p in lista5:\r\n",
    "        lista_muito_relevante.append(p)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "serie_irrelevante = pd.Series(lista_irrelevante)\r\n",
    "tabela_irrelevante = serie_irrelevante.value_counts(True)\r\n",
    "\r\n",
    "serie_neutro = pd.Series(lista_neutro)\r\n",
    "tabela_neutro = serie_neutro.value_counts(True)\r\n",
    "\r\n",
    "serie_relevante = pd.Series(lista_relevante)\r\n",
    "tabela_relevante = serie_relevante.value_counts(True)\r\n",
    "\r\n",
    "serie_muito_relevante = pd.Series(lista_muito_relevante)\r\n",
    "tabela_muito_relevante = serie_muito_relevante.value_counts(True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "P_irrelevante = len(lista_irrelevante)/len(lista_palavras)\r\n",
    "\r\n",
    "P_neutro = len(lista_neutro)/len(lista_palavras)\r\n",
    "\r\n",
    "P_relevante = len(lista_relevante)/len(lista_palavras)\r\n",
    "\r\n",
    "P_muito_relevante = len(lista_muito_relevante)/len(lista_palavras)\r\n",
    "\r\n",
    "print(P_irrelevante)\r\n",
    "\r\n",
    "print(P_neutro)\r\n",
    "\r\n",
    "print(P_relevante)\r\n",
    "\r\n",
    "print(P_muito_relevante)\r\n",
    "\r\n",
    "print(P_irrelevante + P_neutro + P_relevante + P_muito_relevante)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lista_todas_tabelas = [tabela_irrelevante, tabela_neutro, tabela_relevante, tabela_muito_relevante]\r\n",
    "\r\n",
    "lista_todas_listas = [lista_irrelevante, lista_neutro, lista_relevante, lista_muito_relevante]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tabela_irrelevante.to_frame().head(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def classificador(tweet, tabelas, listas):\r\n",
    "    p = 1\r\n",
    "    i = 0\r\n",
    "    soma = 0\r\n",
    "    z = 0\r\n",
    "    lista_resultado = []\r\n",
    "    vezes = 1\r\n",
    "    for tabela in tabelas:\r\n",
    "        soma = 0\r\n",
    "        z += 1\r\n",
    "        vezes = 1\r\n",
    "        for lista in listas:\r\n",
    "            for palavra in tweet.split():\r\n",
    "                if soma >= len(tweet.split()) :\r\n",
    "                    break\r\n",
    "                if palavra in tabela:\r\n",
    "                    p = (1 + tabela[palavra])\r\n",
    "                    soma += 1\r\n",
    "                else:\r\n",
    "                    p = 1\r\n",
    "                    soma += 1\r\n",
    "                i += 1\r\n",
    "                vezes *= p\r\n",
    "        lista_resultado.append(vezes)\r\n",
    "    if lista_resultado.index(max(lista_resultado)) == 0:\r\n",
    "        return 'irrelevante'\r\n",
    "    elif lista_resultado.index(max(lista_resultado)) == 1:\r\n",
    "        return 'neutro'\r\n",
    "    elif lista_resultado.index(max(lista_resultado)) == 2:\r\n",
    "        return 'relevante'\r\n",
    "    elif lista_resultado.index(max(lista_resultado)) == 3:\r\n",
    "        return 'muito relevante'\r\n",
    "\r\n",
    "print(classificador('coco coco coco coco bis', lista_todas_tabelas, lista_todas_listas))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lista_treino_classificada = []\r\n",
    "i = 0\r\n",
    "for a in treino['Treinamento']:\r\n",
    "    lista_treino_classificada.append(classificador(a, lista_todas_tabelas, lista_todas_listas))\r\n",
    "treino[\"classificador\"] = lista_treino_classificada\r\n",
    "treino.head(40)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora vocÃª deve testar o seu classificador com a base de Testes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "test.head()\r\n",
    "teste = test.iloc[:,[0,1]]\r\n",
    "teste['Teste']= teste['Teste'].apply(cleanup)\r\n",
    "\r\n",
    "#tira os @fulano citados\r\n",
    "\r\n",
    "i=0\r\n",
    "\r\n",
    "for t in teste.Teste:\r\n",
    "   limpo = tiraarroba(t)\r\n",
    "   teste.loc[i,'Teste'] = limpo\r\n",
    "   i+=1\r\n",
    "\r\n",
    "#retira os links (https)\r\n",
    "\r\n",
    "i=0\r\n",
    "\r\n",
    "for t in teste.Teste:\r\n",
    "   limpo = tiralink(t)\r\n",
    "   teste.loc[i,'Teste'] = limpo\r\n",
    "   i+=1\r\n",
    "\r\n",
    "teste['Teste'] = teste.Teste.apply(tiralinha)\r\n",
    "\r\n",
    "teste.head()\r\n",
    "\r\n",
    "    \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-205-59578dc44b4f>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teste['Teste']= teste['Teste'].apply(cleanup)\n",
      "C:\\Users\\caiog\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "<ipython-input-205-59578dc44b4f>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teste['Teste'] = teste.Teste.apply(tiralinha)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>NÃ­vel de RelevÃ¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eu quero replay kkkk vamo de novo no bis ðŸ¤£ðŸ¤£ðŸ¤£ðŸ–¤ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>juro acharam uma garrafa de cachaÃ§a e beberam ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sabia que vocÃª ia responder bis fÃ£</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>olÃ¡ queremos muito te ajudar para que possamos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mudaram as fraldas a esse monte de esterco ðŸ¤¢</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  NÃ­vel de RelevÃ¢ncia\n",
       "0  eu quero replay kkkk vamo de novo no bis ðŸ¤£ðŸ¤£ðŸ¤£ðŸ–¤ ...                    1\n",
       "1  juro acharam uma garrafa de cachaÃ§a e beberam ...                    2\n",
       "2                 sabia que vocÃª ia responder bis fÃ£                    1\n",
       "3  olÃ¡ queremos muito te ajudar para que possamos...                    1\n",
       "4       mudaram as fraldas a esse monte de esterco ðŸ¤¢                    1"
      ]
     },
     "metadata": {},
     "execution_count": 205
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "source": [
    "lista_teste_classificada = []\r\n",
    "i = 0\r\n",
    "for tweet in teste[\"Teste\"]:\r\n",
    "    lista_teste_classificada.append(classificador(tweet, lista_todas_tabelas, lista_todas_listas))\r\n",
    "\r\n",
    "teste['classificado'] = lista_teste_classificada\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-207-482c4f8b1581>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teste['classificado'] = lista_teste_classificada\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "source": [
    "def converteemnumero(nivel):\r\n",
    "    if nivel == 'irrelevante':\r\n",
    "        return 1\r\n",
    "    elif nivel == 'neutro':\r\n",
    "        return 2\r\n",
    "    elif nivel == 'relevante':\r\n",
    "        return 3\r\n",
    "    else:\r\n",
    "        return 4\r\n",
    "\r\n",
    "\r\n",
    "valorestestados = []\r\n",
    "for x in teste['NÃ­vel de RelevÃ¢ncia']:\r\n",
    "    valorestestados.append(x)\r\n",
    "\r\n",
    "valorescalculados = []\r\n",
    "for y in teste.classificado:\r\n",
    "    valor = converteemnumero(y)\r\n",
    "    valorescalculados.append(valor)\r\n",
    "\r\n",
    "acertos = 0\r\n",
    "total = 0\r\n",
    "i=0\r\n",
    "while i <= len(valorescalculados)-1:\r\n",
    "    if valorestestados[i] == valorescalculados[i]:\r\n",
    "        acertos+=1\r\n",
    "    total+=1\r\n",
    "    i+=1\r\n",
    "\r\n",
    "qualidade = (acertos/total)*100\r\n",
    "\r\n",
    "print(\" acertou em {}% das vezes\".format(qualidade))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " acertou em 10.285714285714285% das vezes\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Concluindo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separaÃ§Ãµes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## AperfeiÃ§oamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vÃ£o evoluir em conceito dependendo da quantidade de itens avanÃ§ados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformaÃ§Ãµes que nÃ£o afetem a qualidade da informaÃ§Ã£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separaÃ§Ã£o de espaÃ§os entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediÃ¡rias de relevÃ¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adiÃ§Ã£o de mais tweets na base, conforme enunciado. (OBRIGATÃ“RIO PARA TRIOS, sem contar como item avanÃ§ado)\n",
    "* EXPLICOU porquÃª nÃ£o pode usar o prÃ³prio classificador para gerar mais amostras de treinamento\n",
    "* PROPÃ”S diferentes cenÃ¡rios para NaÃ¯ve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicaÃ§Ãµes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separaÃ§Ãµes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÃ“RIO para conceitos A ou A+)"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## ReferÃªncias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "a1c2c12573f1028c7ce9a6508c77f5095ef106d62b2ca7d49ff749989a092ac4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}